{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_shallow_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMB4ckhSUydfzx72z5uCQDY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pejmanrasti/From_Shallow_to_Deep/blob/main/01_Classification_shallow_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdBlub0OLLr-"
      },
      "source": [
        "## Specific concepts that will be covered:\n",
        "In the process, we will build practical experience and develop intuition around the concepts classification\n",
        "\n",
        "\n",
        "\n",
        "## We will follow the general machine learning workflow:\n",
        "\n",
        "1. Examine and understand data\n",
        "2. Build an input pipeline\n",
        "3. Build our models\n",
        "4. Train our models\n",
        "5. Test our models\n",
        "6. Improve our model/Repeat the process\n",
        "\n",
        "<hr>\n",
        "\n",
        "**Before you begin**\n",
        "\n",
        "Before running the code in this notebook, reset the runtime by going to **Kernel -> Restart & clear output** in the menu above. If you have been working through several notebooks, this will help you avoid reaching memory limits.\n",
        "\n",
        "© Aurélien Géron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSr87zKFLidv"
      },
      "source": [
        "# Importing Libraries\n",
        "\n",
        "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH2U3lqsLhCz"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "Our_Task = \"classification\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", Our_Task)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC0iUWh-Ke0M"
      },
      "source": [
        "# Reading and undrestanding our data\n",
        "\n",
        "Our goal is to construct and train a classification mosel on thousands of images of handwritten digits so that it may successfully identify others when presented. The data that will be incorporated is the MNIST database which contains 60,000 images for training and 10,000 test images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejXWJw-0OSx-"
      },
      "source": [
        "\n",
        "<img src=\"https://camo.githubusercontent.com/01c057a753e92a9bc70b8c45d62b295431851c09cffadf53106fc0aea7e2843f/687474703a2f2f692e7974696d672e636f6d2f76692f3051493378675875422d512f687164656661756c742e6a7067\" >"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKi6-Nj1Ke0N"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "mnist.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvLptfGxKe0N"
      },
      "source": [
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enk3WT4IKe0O"
      },
      "source": [
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q_WBo5HKe0O"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import random \n",
        "\n",
        "n = random.randint(0,70000)\n",
        "random_digit = X[n]\n",
        "random_digit_2D = random_digit.reshape(28, 28)\n",
        "plt.imshow(random_digit_2D, cmap=mpl.cm.binary)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "save_fig(\"Random_digit_plot\")\n",
        "plt.title(\"Label = \" + y[n])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIvZx1C9Ke0O"
      },
      "source": [
        "y = y.astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ycPVhKDKe0P"
      },
      "source": [
        "X_train, X_test, y_train, y_test = X[:55000], X[55000:], y[:55000], y[55000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4mU5RaqKe0P"
      },
      "source": [
        "# Binary classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orNTR1hpKe0P"
      },
      "source": [
        "# Make all labels equal to seven as true and the rest as fault \n",
        "y_keep_7 = (y_train == 7)\n",
        "y_test_keep_7 = (y_test == 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlka9kmrKe0Q"
      },
      "source": [
        "There are a couple of classifiers available for this task but we would start with the [stochastic gradient descent (SGD)](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkHl114eKe0Q"
      },
      "source": [
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
        "sgd_clf.fit(X_train, y_keep_7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz-eXl_EKe0Q"
      },
      "source": [
        "sgd_clf.predict([random_digit])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_DxDPmT1OkI"
      },
      "source": [
        "Cross-validation is a statistical method used to estimate the skill of machine learning models.\n",
        "\n",
        "It is commonly used in applied machine learning to compare and select a model for a given predictive modeling problem because it is easy to understand, easy to implement, and results in skill estimates that generally have a lower bias than other methods.\n",
        "\n",
        "\n",
        "<img src=https://scikit-learn.org/stable/_images/grid_search_cross_validation.png>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKzQvQlMKe0Q"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "cross_val_score(sgd_clf, X_train, y_keep_7, cv=5, scoring=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo_rw4qsKe0Q"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "class Never7Classifier(BaseEstimator):\n",
        "    def fit(self, X, y=None):\n",
        "        pass\n",
        "    def predict(self, X):\n",
        "        return np.zeros((len(X), 1), dtype=bool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qI7h18AKe0Q"
      },
      "source": [
        "never_7_clf = Never7Classifier()\n",
        "cross_val_score(never_7_clf, X_train, y_keep_7, cv=5, scoring=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGBJQJGhKe0R"
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "y_train_pred = cross_val_predict(sgd_clf, X_train, y_keep_7, cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTbb7apC6v6O"
      },
      "source": [
        "A confusion matrix is a summary of prediction results on a classification problem. The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix.\n",
        "<img src=http://rasbt.github.io/mlxtend/user_guide/evaluate/confusion_matrix_files/confusion_matrix_1.png >"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoaWrahdKe0R"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_keep_7, y_train_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBDGkWONKe0R"
      },
      "source": [
        "y_train_perfect_predictions = y_keep_7  # pretend we reached perfection\n",
        "confusion_matrix(y_keep_7, y_train_perfect_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SVPQDe5Ke0R"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "precision_score(y_keep_7, y_train_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuDBLtgwKe0R"
      },
      "source": [
        "cm = confusion_matrix(y_keep_7, y_train_pred)\n",
        "cm[1, 1] / (cm[0, 1] + cm[1, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6Z6zGhmKe0R"
      },
      "source": [
        "recall_score(y_keep_7, y_train_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmbPhCJVKe0R"
      },
      "source": [
        "cm[1, 1] / (cm[1, 0] + cm[1, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZzeb2XnKe0R"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(y_keep_7, y_train_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0v9vHNZKe0R"
      },
      "source": [
        "cm[1, 1] / (cm[1, 1] + (cm[1, 0] + cm[0, 1]) / 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8keQJpDxKe0R"
      },
      "source": [
        "y_scores = sgd_clf.decision_function([random_digit])\n",
        "y_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adK1lCo7Ke0R"
      },
      "source": [
        "threshold = 0\n",
        "y_some_digit_pred = (y_scores > threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_Kst4f_Ke0R"
      },
      "source": [
        "y_some_digit_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpnV2YFOKe0S"
      },
      "source": [
        "threshold = 8000\n",
        "y_some_digit_pred = (y_scores > threshold)\n",
        "y_some_digit_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbKVeR4hShIG"
      },
      "source": [
        "# Multiclass classification\n",
        "\n",
        "Some algorithms (such as Random Forest classifiers or naive Bayes classifiers) are capable of handling multiple classes directly. Others (such as Support Vector Machine classifiers or Linear classifiers) are strictly binary classifiers. However, there are various strategies that you can use to perform multiclass classification using multiple binary classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6rRJGAiShIG"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_clf = SVC(gamma=\"auto\", random_state=42)\n",
        "svm_clf.fit(X_train[:1000], y_train[:1000]) # y_train, not y_train_5\n",
        "svm_clf.predict([random_digit])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42T0x2s-ShIG"
      },
      "source": [
        "some_digit_scores = svm_clf.decision_function([random_digit])\n",
        "some_digit_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuuJpfbrShIG"
      },
      "source": [
        "np.argmax(some_digit_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBWQqF_CShIH"
      },
      "source": [
        "svm_clf.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWpWBBgbShIH"
      },
      "source": [
        "svm_clf.classes_[5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of63ZM37ShIH"
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "ovr_clf = OneVsRestClassifier(SVC(gamma=\"auto\", random_state=42))\n",
        "ovr_clf.fit(X_train[:1000], y_train[:1000])\n",
        "ovr_clf.predict([random_digit])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvot6aQOShIH"
      },
      "source": [
        "len(ovr_clf.estimators_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW17WsaqShIH"
      },
      "source": [
        "sgd_clf.fit(X_train, y_train) #trains the SGDClassifier on the training set\n",
        "sgd_clf.predict([random_digit])\n",
        "\n",
        "#Scikit-Learn actually trained 10 binary classifiers, got their decision scores for the\n",
        "#image, and selected the class with the highest score."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQspjWW5ShIH"
      },
      "source": [
        "# show the result of all binary classifications\n",
        "\n",
        "sgd_clf.decision_function([random_digit])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLdTsA_EShIH"
      },
      "source": [
        "**Warning**: the following two cells may take close to 30 minutes to run, or more depending on your hardware."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmus62FrShIH"
      },
      "source": [
        "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVnGFfJep9nS"
      },
      "source": [
        "One of the most important transformations you need to apply to your data is feature scaling. With few exceptions, Machine Learning algorithms don’t perform well when the input numerical attributes have very different scales.\n",
        "There are two common ways to get all attributes to have the same scale: min-max scaling and standardization\n",
        "\n",
        "Min-max: they end up ranging from 0 to 1\n",
        "\n",
        "Standardization: first it subtracts the mean value, and then it divides by the standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqCPgyxvShIH"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
        "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_z93GnKn2V3"
      },
      "source": [
        "# Your Task, Train a random Forest classifier on our data\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfWJcrsoShIH"
      },
      "source": [
        "# Error analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_uJ3cnBShIH"
      },
      "source": [
        "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
        "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
        "conf_mx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llb2FUJUShIH"
      },
      "source": [
        "# since sklearn 0.22, you can use sklearn.metrics.plot_confusion_matrix()\n",
        "def plot_confusion_matrix(matrix):\n",
        "    \"\"\"If you prefer color and a colorbar\"\"\"\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(matrix)\n",
        "    fig.colorbar(cax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPH3KyDFShII"
      },
      "source": [
        "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
        "save_fig(\"confusion_matrix_plot\", tight_layout=False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3X3yEjmShII"
      },
      "source": [
        "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
        "norm_conf_mx = conf_mx / row_sums"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMlYEcw_ShII"
      },
      "source": [
        "np.fill_diagonal(norm_conf_mx, 0)\n",
        "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
        "save_fig(\"confusion_matrix_errors_plot\", tight_layout=False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcCMnODRShII"
      },
      "source": [
        "cl_a, cl_b = 3, 5\n",
        "X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\n",
        "X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\n",
        "X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\n",
        "X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L91Z31rs-Al"
      },
      "source": [
        "def plot_digits(instances, images_per_row=10, **options):\n",
        "    size = 28\n",
        "    images_per_row = min(len(instances), images_per_row)\n",
        "    images = [instance.reshape(size,size) for instance in instances]\n",
        "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
        "    row_images = []\n",
        "    n_empty = n_rows * images_per_row - len(instances)\n",
        "    images.append(np.zeros((size, size * n_empty)))\n",
        "    for row in range(n_rows):\n",
        "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
        "        row_images.append(np.concatenate(rimages, axis=1))\n",
        "    image = np.concatenate(row_images, axis=0)\n",
        "    plt.imshow(image, cmap = mpl.cm.binary, **options)\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xCCjhY4tBjf"
      },
      "source": [
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)\n",
        "plt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)\n",
        "plt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)\n",
        "plt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)\n",
        "save_fig(\"error_analysis_digits_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2bUoxP4ShII"
      },
      "source": [
        "# Multilabel classification\n",
        "\n",
        "In some cases you may want your classifier to output multiple classes for each instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu6p-D4gShII"
      },
      "source": [
        "#This block creates a y_multilabel array containing two target labels for each digit\n",
        "#image: the first indicates whether or not the digit is large (7, 8, or 9) and the second\n",
        "#indicates whether or not it is odd.\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "y_train_large = (y_train >= 7)\n",
        "y_train_odd = (y_train % 2 == 1)\n",
        "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
        "\n",
        "knn_clf = KNeighborsClassifier()\n",
        "knn_clf.fit(X_train, y_multilabel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FJkMSjGShII"
      },
      "source": [
        "print(y[n]) #our random digit\n",
        "knn_clf.predict([random_digit])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd-rsWBmShII"
      },
      "source": [
        "**Warning**: the following cell may take a very long time (possibly hours depending on your hardware)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU8ilW0aShII"
      },
      "source": [
        "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n",
        "f1_score(y_multilabel, y_train_knn_pred, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GLNEfLcwsOs"
      },
      "source": [
        "# Multioutput classification\n",
        "It is simply a generalization of multilabel classification where each label can be multiclass (i.e., it can have more than two possible values)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARVnkh6GwsOs"
      },
      "source": [
        "noise = np.random.randint(0, 100, (len(X_train), 784))\n",
        "X_train_mod = X_train + noise\n",
        "noise = np.random.randint(0, 100, (len(X_test), 784))\n",
        "X_test_mod = X_test + noise\n",
        "y_train_mod = X_train\n",
        "y_test_mod = X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCc3Wr2lzhnR"
      },
      "source": [
        "def plot_digit(data):\n",
        "    image = data.reshape(28, 28)\n",
        "    plt.imshow(image, cmap = mpl.cm.binary,\n",
        "               interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHUMgm-gwsOs"
      },
      "source": [
        "some_index = 8\n",
        "plt.subplot(121); plot_digit(X_test_mod[some_index])\n",
        "plt.subplot(122); plot_digit(y_test_mod[some_index])\n",
        "save_fig(\"noisy_digit_example_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn78Y869wsOs"
      },
      "source": [
        "knn_clf.fit(X_train_mod, y_train_mod)\n",
        "clean_digit = knn_clf.predict([X_test_mod[some_index]])\n",
        "plot_digit(clean_digit)\n",
        "save_fig(\"cleaned_digit_example_plot\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZkXKg_r0rot"
      },
      "source": [
        "# Task: Re-do the classification process on the Cifar-10 database\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "(train_X, train_y), (test_X, test_y) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}