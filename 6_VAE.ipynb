{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOc9JFxjK1AvjonEu6orQwB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pejmanrasti/From_Shallow_to_Deep/blob/main/6_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tsLLo0Tfrtx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.utils as vutils\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Import Tensorboard\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the VAE model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, image_size):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 1024, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(1024 * (image_size // 16)**2, 2048)\n",
        "        self.fc2 = nn.Linear(2048, 2048)\n",
        "        self.fc3 = nn.Linear(2048, 2048)\n",
        "        self.fc4 = nn.Linear(2048, 2048)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(2048, 512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        return self.fc2(x), self.fc3(x)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps.mul(std).add_(mu)\n",
        "\n",
        "    def decode(self, z):\n",
        "        z = self.fc4(z)\n",
        "        z = z.view(z.size(0), 2048, 1, 1)\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n"
      ],
      "metadata": {
        "id": "fTA6qb1wfxiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load images from local folder\n",
        "folder = 'path/to/folder'\n",
        "transform = transforms.Compose([transforms.Resize((512, 512)), transforms.ToTensor()])\n",
        "dataset = ImageFolder(folder,transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "XpsMmMuMiV7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer\n",
        "image_size = 512\n",
        "vae = VAE(image_size)\n",
        "reconstruction_loss = nn.MSELoss()\n",
        "kl_loss = lambda mu, logvar: -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "optimizer = optim.Adam(vae.parameters())"
      ],
      "metadata": {
        "id": "rn4mQDJtijdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define early stopping and model checkpointing\n",
        "early_stopping = EarlyStopping(patience=5)\n",
        "checkpoint = ModelCheckpoint('vae.pth', save_best_only=True, save_weights_only=True)\n",
        "\n",
        "# Define Tensorboard writer\n",
        "writer = SummaryWriter()"
      ],
      "metadata": {
        "id": "hYGTSbH8igxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        images = images.to(device)\n",
        "        recon_images, mu, logvar = vae(images)\n",
        "        loss = reconstruction_loss(recon_images, images) + kl_loss(mu, logvar)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Log images to Tensorboard\n",
        "        writer.add_images('Generated Images', recon_images, epoch)\n",
        "        \n",
        "    # Check for early stopping and save best model\n",
        "    early_stopping(loss, vae)\n",
        "    checkpoint(loss, vae)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping at epoch {}\".format(epoch))\n",
        "        break\n",
        "    # Print the loss every 10 epochs and log to Tensorboard\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(\"Epoch [{}/{}], Loss: {:.4f}\".format(epoch+1, num_epochs, loss.item()))\n",
        "        writer.add_scalar('Loss', loss.item(), epoch)"
      ],
      "metadata": {
        "id": "pcbV8zyQicoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "vae.load_state_dict(torch.load('vae.pth'))\n",
        "\n",
        "# Close Tensorboard writer\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "FRS5FeAciYfb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}